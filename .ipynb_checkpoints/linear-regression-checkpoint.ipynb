{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and Y sample data => y = x의 선분이 나올 것을 예측할 수 있다.\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "# make W and b for H(x) = Wx + b\n",
    "W = tf.Variable(tf.random.normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our hypothesis XW + b\n",
    "hypothesis = x_train*W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# const/loss function => 차이를 평균 내준다.\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    cost를 최소화 한다!\n",
    "    텐서플로우가 알아서 최소 cost를 가지는 W와 b를 조정한다.\n",
    "    이 부분은 텐서플로우 라이브러리가 알아서 해주는 magic이라 생각하자.\n",
    "\"\"\"\n",
    "optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    위에서 만든 그래프를 세션을 통해 동작시킨다.\n",
    "    W와 b와 같은 텐서플로우 변수를 사용하기 위해 초기화한다.\n",
    "\"\"\"\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.70556647 [0.955565] [-0.7503261]\n",
      "20 0.054755215 [1.2268118] [-0.59666026]\n",
      "40 0.044416 [1.2417815] [-0.55734515]\n",
      "60 0.04029112 [1.232859] [-0.53007835]\n",
      "80 0.03659262 [1.222148] [-0.5050644]\n",
      "100 0.03323401 [1.21173] [-0.4813186]\n",
      "120 0.030183667 [1.2017814] [-0.45869747]\n",
      "140 0.02741327 [1.1922987] [-0.4371402]\n",
      "160 0.024897195 [1.1832615] [-0.41659626]\n",
      "180 0.022612028 [1.1746489] [-0.39701775]\n",
      "200 0.0205366 [1.166441] [-0.37835944]\n",
      "220 0.018651677 [1.1586189] [-0.360578]\n",
      "240 0.016939752 [1.1511643] [-0.34363222]\n",
      "260 0.015384965 [1.1440604] [-0.3274828]\n",
      "280 0.013972874 [1.13729] [-0.31209236]\n",
      "300 0.012690379 [1.1308378] [-0.29742518]\n",
      "320 0.0115256095 [1.124689] [-0.28344733]\n",
      "340 0.010467748 [1.118829] [-0.27012634]\n",
      "360 0.009506963 [1.1132444] [-0.25743133]\n",
      "380 0.00863438 [1.1079223] [-0.24533299]\n",
      "400 0.0078418935 [1.1028506] [-0.23380324]\n",
      "420 0.007122133 [1.0980169] [-0.22281538]\n",
      "440 0.00646843 [1.0934105] [-0.21234386]\n",
      "460 0.0058747325 [1.0890205] [-0.2023645]\n",
      "480 0.005335528 [1.084837] [-0.1928541]\n",
      "500 0.0048458218 [1.0808501] [-0.18379082]\n",
      "520 0.0044010486 [1.0770502] [-0.17515334]\n",
      "540 0.003997109 [1.0734292] [-0.16692178]\n",
      "560 0.003630232 [1.0699782] [-0.15907705]\n",
      "580 0.0032970347 [1.0666895] [-0.15160102]\n",
      "600 0.0029944226 [1.0635554] [-0.1444763]\n",
      "620 0.0027195818 [1.0605687] [-0.13768654]\n",
      "640 0.0024699713 [1.0577221] [-0.13121583]\n",
      "660 0.0022432676 [1.0550094] [-0.12504917]\n",
      "680 0.0020373736 [1.0524241] [-0.11917231]\n",
      "700 0.001850373 [1.0499603] [-0.11357159]\n",
      "720 0.0016805377 [1.0476124] [-0.10823417]\n",
      "740 0.0015262872 [1.0453748] [-0.10314753]\n",
      "760 0.0013861979 [1.0432423] [-0.09829994]\n",
      "780 0.001258975 [1.0412104] [-0.09368032]\n",
      "800 0.001143424 [1.0392734] [-0.08927784]\n",
      "820 0.0010384725 [1.0374277] [-0.08508205]\n",
      "840 0.00094315526 [1.0356687] [-0.08108349]\n",
      "860 0.0008565909 [1.0339925] [-0.07727284]\n",
      "880 0.00077796826 [1.0323949] [-0.07364128]\n",
      "900 0.0007065621 [1.0308723] [-0.07018039]\n",
      "920 0.00064171135 [1.0294214] [-0.06688209]\n",
      "940 0.0005828097 [1.0280389] [-0.06373885]\n",
      "960 0.00052932004 [1.0267212] [-0.06074341]\n",
      "980 0.00048073533 [1.0254654] [-0.05788872]\n",
      "1000 0.0004366108 [1.0242685] [-0.05516815]\n",
      "1020 0.0003965383 [1.023128] [-0.05257543]\n",
      "1040 0.00036014314 [1.0220411] [-0.05010464]\n",
      "1060 0.00032708806 [1.0210052] [-0.04774997]\n",
      "1080 0.0002970648 [1.020018] [-0.04550584]\n",
      "1100 0.00026979737 [1.0190772] [-0.0433671]\n",
      "1120 0.00024503455 [1.0181806] [-0.04132893]\n",
      "1140 0.00022254307 [1.0173262] [-0.03938658]\n",
      "1160 0.0002021179 [1.0165119] [-0.03753556]\n",
      "1180 0.0001835662 [1.0157359] [-0.03577149]\n",
      "1200 0.00016671717 [1.0149963] [-0.03409031]\n",
      "1220 0.00015141498 [1.0142915] [-0.03248816]\n",
      "1240 0.00013751896 [1.01362] [-0.03096136]\n",
      "1260 0.0001248954 [1.0129799] [-0.02950631]\n",
      "1280 0.0001134327 [1.0123699] [-0.02811962]\n",
      "1300 0.00010302166 [1.0117886] [-0.02679811]\n",
      "1320 9.3565875e-05 [1.0112345] [-0.02553872]\n",
      "1340 8.4978354e-05 [1.0107067] [-0.02433849]\n",
      "1360 7.717966e-05 [1.0102036] [-0.0231948]\n",
      "1380 7.0095884e-05 [1.0097239] [-0.02210481]\n",
      "1400 6.366177e-05 [1.0092669] [-0.02106591]\n",
      "1420 5.781802e-05 [1.0088314] [-0.02007585]\n",
      "1440 5.2512e-05 [1.0084163] [-0.01913234]\n",
      "1460 4.7691326e-05 [1.0080208] [-0.01823319]\n",
      "1480 4.331469e-05 [1.0076438] [-0.01737624]\n",
      "1500 3.9338807e-05 [1.0072846] [-0.01655963]\n",
      "1520 3.572887e-05 [1.0069424] [-0.01578143]\n",
      "1540 3.2449378e-05 [1.0066161] [-0.01503982]\n",
      "1560 2.947053e-05 [1.0063051] [-0.014333]\n",
      "1580 2.6766103e-05 [1.0060087] [-0.01365936]\n",
      "1600 2.4308998e-05 [1.0057263] [-0.0130174]\n",
      "1620 2.2077627e-05 [1.0054573] [-0.01240565]\n",
      "1640 2.0052266e-05 [1.005201] [-0.0118227]\n",
      "1660 1.8211533e-05 [1.0049566] [-0.01126717]\n",
      "1680 1.6540178e-05 [1.0047235] [-0.01073767]\n",
      "1700 1.502212e-05 [1.0045016] [-0.01023305]\n",
      "1720 1.3643075e-05 [1.00429] [-0.00975215]\n",
      "1740 1.2391178e-05 [1.0040884] [-0.00929386]\n",
      "1760 1.1253927e-05 [1.0038962] [-0.00885713]\n",
      "1780 1.0221335e-05 [1.0037133] [-0.00844088]\n",
      "1800 9.282922e-06 [1.0035386] [-0.00804422]\n",
      "1820 8.431008e-06 [1.0033724] [-0.00766617]\n",
      "1840 7.657122e-06 [1.0032139] [-0.00730589]\n",
      "1860 6.954522e-06 [1.0030628] [-0.00696255]\n",
      "1880 6.3161074e-06 [1.002919] [-0.00663535]\n",
      "1900 5.7362417e-06 [1.0027817] [-0.00632353]\n",
      "1920 5.2098762e-06 [1.002651] [-0.00602636]\n",
      "1940 4.731826e-06 [1.0025265] [-0.00574318]\n",
      "1960 4.297601e-06 [1.0024078] [-0.00547333]\n",
      "1980 3.903359e-06 [1.0022947] [-0.00521615]\n",
      "2000 3.5452279e-06 [1.0021869] [-0.00497109]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    선분을 최적화하는 과정을 진행한다.\n",
    "    20의 배수마다 그 값을 출력해 본다.\n",
    "\"\"\"\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    \n",
    "    if(step % 20 == 0):\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
